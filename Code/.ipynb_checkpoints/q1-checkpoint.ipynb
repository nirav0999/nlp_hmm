{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "def appendToCSV(filepath,row):\n",
    "\twith open(filepath,\"a\",buffering = 1) as csvfile:\n",
    "\t\twriter = csv.writer(csvfile)\n",
    "\t\twrtiter.writerow(row)\n",
    "\n",
    "def openCSVfile(filepath,delim = \",\"):\n",
    "\twith open(filepath,\"r\") as csvfile:\n",
    "\t\trows =  csv.reader(csvfile,delimiter = delim)\n",
    "\t\treturn list(rows)\n",
    "    \n",
    "def dumpJsonFile(filepath,dictionary):\n",
    "\tprint(\"Dumping a dictionary to filepath\",filepath,\"...............\")\n",
    "\twith open(filepath,\"w+\") as jsonFile:\n",
    "\t\tjson.dump(dictionary,jsonFile,indent=4,sort_keys =True)\n",
    "\tprint(\"Dumped Successfully\")\n",
    "\n",
    "def LoadJsonFile(filepath):\n",
    "\tprint(\"Loading a dictionary to filepath\",filepath,\"...............\")\n",
    "\tdictionary = {}\n",
    "\twith open(filepath) as jsonFile:\n",
    "\t\tdictionary = json.load(jsonFile)\n",
    "\tprint(\"Loaded Successfully\")\n",
    "\treturn dictionary\n",
    "\n",
    "def loadPickleFile(filepath):\n",
    "\tprint(\"Loading the pickle file from\",filepath,\"...........\")\n",
    "\tpickle_in = open(filepath,\"rb\")\n",
    "\texample_dict = pickle.load(pickle_in)\n",
    "\tprint(\"Loaded the pickle File\")\n",
    "\treturn example_dict\n",
    "\n",
    "def dumpPickleFile(data,filepath):\n",
    "\tpickle_out = open(filepath,\"wb\")\n",
    "\tprint(\"Dumping the Pickle file into \",filepath,\"...........\")\n",
    "\tpickle.dump(data, pickle_out)\n",
    "\tprint(\"Dumped the pickle File\")\n",
    "\tpickle_out.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertTags(dictionary,ftag,stag = None,gram = 2):\n",
    "    \"\"\"\n",
    "    Input - \n",
    "    Output - \n",
    "    Returns -\n",
    "    \"\"\"\n",
    "    if gram == 2:\n",
    "        if ftag in dictionary:\n",
    "            if stag in dictionary[ftag]:\n",
    "                dictionary[ftag][stag] += 1\n",
    "            else:\n",
    "                dictionary[ftag][stag] = 1\n",
    "        else:\n",
    "            dictionary[ftag] = {stag : 1}\n",
    "        return dictionary\n",
    "    elif gram == 1:\n",
    "        if ftag in dictionary:\n",
    "            dictionary[ftag] += 1\n",
    "        else:\n",
    "            dictionary[ftag] = 1\n",
    "    return dictionary\n",
    "\n",
    "\n",
    "def MakeMatrices(rows):\n",
    "    bigramTagDict = {}\n",
    "    unigramTagDict = {}\n",
    "    unigramWordDict = {}\n",
    "    wordTagDict = {}\n",
    "    endingIndex = -1\n",
    "    for row_no in range(0,len(rows) - 1):\n",
    "        currentRow = rows[row_no]\n",
    "        nextRow = rows[row_no + 1]\n",
    "        #print(\"Current Row = \",currentRow)\n",
    "        #print(\"Next Row = \",nextRow)\n",
    "        if currentRow[0] == nextRow[0] == \"<startTag>\":\n",
    "            endingIndex = row_no\n",
    "            break\n",
    "        if currentRow[0] == \"<startTag>\":\n",
    "            \n",
    "            bigramTagDict = insertTags(bigramTagDict,\"<startTag>\",nextRow[1],2)\n",
    "            unigramTagDict = insertTags(unigramTagDict,\"<startTag>\",gram = 1)\n",
    "            unigramWordDict = insertTags(unigramWordDict,\"<startTag>\",gram = 1)\n",
    "        elif currentRow[0] == \"<endTag>\":\n",
    "            unigramTagDict = insertTags(unigramTagDict,\"<endTag>\",gram = 1)\n",
    "            unigramWordDict = insertTags(unigramWordDict,\"<endTag>\",gram = 1)\n",
    "            continue\n",
    "        else:\n",
    "            bigramTagDict = insertTags(bigramTagDict,currentRow[1],nextRow[1],2)\n",
    "            unigramTagDict = insertTags(unigramTagDict,currentRow[1],gram = 1)\n",
    "            unigramWordDict = insertTags(unigramWordDict,currentRow[0],gram = 1)\n",
    "            wordTagDict = insertTags(wordTagDict,currentRow[0],currentRow[1],2)\n",
    "    #print(bigramTagDict)\n",
    "    #print(\"--------------------------------------\")\n",
    "    #print(unigramTagDict)\n",
    "    #print(\"--------------------------------------\")\n",
    "    #print(wordTagDict)\n",
    "    rows = rows[:endingIndex]\n",
    "    return rows,unigramWordDict,unigramTagDict,bigramTagDict,wordTagDict\n",
    "\n",
    "def readTrainingSet(filepath = \"../Dataset/Training set_HMM.txt\"):\n",
    "    rows = openCSVfile(filepath,\"\\t\")\n",
    "    for row_no in range(len(rows)):\n",
    "        row = rows[row_no]\n",
    "        nfitems = len(row)\n",
    "        if nfitems == 0:\n",
    "            rows[row_no] = [\"<startTag>\",\"<startTag>\"]\n",
    "        else:\n",
    "            if rows[row_no][0] == \".\":\n",
    "                rows[row_no] = [\"<endTag>\",\"<endTag>\"]\n",
    "    rows.insert(0,[\"<startTag>\",\"<startTag>\"])\n",
    "    return rows\n",
    "\n",
    "def readTestingSet(filepath = \"../Dataset/Test_HMM.txt\"):\n",
    "    rows = []\n",
    "    with open(filepath) as file:\n",
    "        r1 = file.readlines()\n",
    "    for r in r1:\n",
    "        r = r.strip(\"\\n\")\n",
    "        rows.append(r)\n",
    "    for row_no in range(len(rows)):\n",
    "        row = rows[row_no]\n",
    "        nfitems = len(row)\n",
    "        if nfitems == 0:\n",
    "            rows[row_no] = \"<startTag>\"\n",
    "        else:\n",
    "            if rows[row_no][0] == \".\":\n",
    "                rows[row_no] = \"<endTag>\"\n",
    "    rows.insert(0,\"<startTag>\")\n",
    "    return rows   \n",
    "\n",
    "def calcTransitionProbs(unigramTagDict,bigramTagDict):\n",
    "    bigramTagProbDict = {}\n",
    "    for fword in bigramTagDict.keys():\n",
    "        bigramTagProbDict[fword] = {} \n",
    "        for sword in bigramTagDict[fword].keys():\n",
    "            prob = float(bigramTagDict[fword][sword])/float(unigramTagDict[fword])\n",
    "            logprob = math.log(prob,10)\n",
    "            bigramTagProbDict[fword][sword] = logprob\n",
    "    return bigramTagProbDict\n",
    "\n",
    "            \n",
    "def numberOfWords(unigramTagDict):\n",
    "    totalWords = 0\n",
    "    falseWords = [\"<endTag>\",\"<startTag>\"]\n",
    "    for fword in unigramTagDict.keys():\n",
    "        if fword not in falseWords:\n",
    "            totalWords += unigramTagDict[fword]\n",
    "    return totalWords,(len(unigramTagDict) - 2)\n",
    "    \n",
    "def calcWordTagProbs(unigramTagDict):\n",
    "    totalWords,uniqueWords = numberOfWords(unigramTagDict)\n",
    "    unigramTagProbDict = {}\n",
    "    for word in unigramTagDict.keys():\n",
    "        prob = float(unigramTagDict[word])/float(totalWords)\n",
    "        logprob = math.log(prob,10)\n",
    "        unigramTagProbDict[word] = logprob\n",
    "    return unigramTagProbDict\n",
    "            \n",
    "def modifyOutput(filename = \"OUTPUT.txt\"):\n",
    "    finallines = []\n",
    "    with open(filename) as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip(\"\\n\")\n",
    "            line1 = line.split(\"\\t\")\n",
    "            #print(line1)\n",
    "            if line1[0] == \"<startTag>\":\n",
    "                finallines.append([])\n",
    "            elif line1[0] == \"<endTag>\":\n",
    "                finallines.append([\".\",\".\"])\n",
    "            else:\n",
    "                finallines.append(line1)\n",
    "    df = pd.DataFrame(finallines)\n",
    "    print(\"FInal Results = \")\n",
    "    print(df)\n",
    "    df.to_csv(\"RESULTS.txt\",sep = \"\\t\")\n",
    "                \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = readTrainingSet()\n",
    "rows1 = readTestingSet()\n",
    "#print(rows1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "rows,unigramWordDict,unigramTagDict,bigramTagDict,wordTagDict = MakeMatrices(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tokens = [\"<startTag>\",\"the\",\"distance\",\"does\",\"not\",\"matter\",\"<endTag>\"]\n",
    "tokens = rows1\n",
    "bigramTagProbDict = calcTransitionProbs(unigramTagDict,bigramTagDict)\n",
    "unigramTagProbDict = calcWordTagProbs(unigramTagDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FInal Results = \n",
      "             0     1\n",
      "0         None  None\n",
      "1            i   PRP\n",
      "2           'd    MD\n",
      "3         like    VB\n",
      "4           to    TO\n",
      "5           go    VB\n",
      "6           to    TO\n",
      "7            a    DT\n",
      "8        fancy    JJ\n",
      "9   restaurant    NN\n",
      "10           .     .\n",
      "11        None  None\n",
      "12           i   PRP\n",
      "13          'd    MD\n",
      "14        like    VB\n",
      "15      french    JJ\n",
      "16        food    NN\n",
      "17           .     .\n",
      "18        None  None\n",
      "19        next    JJ\n",
      "20    thursday    NN\n",
      "21           .     .\n",
      "22        None  None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nirav/.local/lib/python3.6/site-packages/ipykernel_launcher.py:62: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "def getUniqueTokens(unigramTagDict):\n",
    "    falseTags = []\n",
    "    uniqueTags = []\n",
    "    for key in unigramTagDict.keys():\n",
    "        if key not in falseTags:\n",
    "            uniqueTags.append(key)\n",
    "    uniqueTags.sort()\n",
    "    return uniqueTags\n",
    "\n",
    "def calcProbablities(tokens,unigramWordDict,unigramTagDict,bigramTagProbDict,bigramTagDict,wordTagDict,k = 1):\n",
    "    falseTags = [\"<endTag>\",\"<startTag>\"]\n",
    "    uniqueTags = getUniqueTokens(unigramTagDict)\n",
    "    nftags = len(uniqueTags)\n",
    "    nftokens = len(tokens)\n",
    "    colHeadings = {}\n",
    "    for i in range(len(tokens)):\n",
    "        colHeadings[i] = tokens[i]\n",
    "    probMatrice = []\n",
    "    for i in range(nftags):\n",
    "        newM = []\n",
    "        for i in range(nftokens):\n",
    "            newM.append(0)\n",
    "        probMatrice.append(newM)\n",
    "    prevWord = \"<startTag>\"\n",
    "    for token_no in range(1,len(tokens)):\n",
    "        currWord = tokens[token_no]\n",
    "        for tag_no_old in range(len(uniqueTags)):\n",
    "            prevTag = uniqueTags[tag_no_old]\n",
    "            for tag_no in range(len(uniqueTags)):\n",
    "                currTag = uniqueTags[tag_no]\n",
    "                p = 0\n",
    "                p1 = 0\n",
    "                if prevTag in bigramTagDict:\n",
    "                    if currTag not in bigramTagDict[prevTag]:\n",
    "                        p = 0\n",
    "                    else:\n",
    "                        p =  10**bigramTagProbDict[prevTag][currTag]\n",
    "                else:\n",
    "                    p = 0\n",
    "                TagCount = unigramTagDict[currTag]\n",
    "                if currWord not in wordTagDict:\n",
    "                    p1 = float(k)/float(TagCount + k*nftags)\n",
    "                else:\n",
    "                    if currTag not in wordTagDict[currWord]:\n",
    "                        p1 = 0\n",
    "                    else:\n",
    "                        p1 = float(wordTagDict[currWord][currTag] + k)/float(TagCount + k*nftags)\n",
    "                if token_no - 1 == 0:\n",
    "                    newProb = p * p1\n",
    "                else:\n",
    "                    newProb = p * p1 * probMatrice[tag_no_old][token_no - 1]\n",
    "                if newProb > probMatrice[tag_no][token_no]:\n",
    "                    probMatrice[tag_no][token_no] = newProb\n",
    "                    #maxMatrice[tag_no][token_no] = prevTag \n",
    "    rowDict = {}\n",
    "    for i in range(nftags):\n",
    "        rowDict[i] = uniqueTags[i]\n",
    "    df1 = pd.DataFrame(probMatrice)\n",
    "    df1.rename(index = rowDict,inplace = True)\n",
    "    df2 = df1.idxmax(axis = 0) \n",
    "    df2.rename(index = colHeadings,inplace = True)\n",
    "    df2.to_csv(\"OUTPUT.txt\",sep = \"\\t\")\n",
    "    modifyOutput()\n",
    "    #print(df2)\n",
    "\n",
    "calcProbablities(tokens,unigramWordDict,unigramTagDict,bigramTagProbDict,bigramTagDict,wordTagDict,k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
